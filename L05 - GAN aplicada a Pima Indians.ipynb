{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5db0103-3071-471b-aaae-b81b30282db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, LeakyReLU, BatchNormalization, Reshape, Flatten\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00c51d15-64df-4a2f-ba14-0f025a320754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el dataset desde OpenML\n",
    "diabetes = fetch_openml(name='diabetes', version=1, as_frame=True)\n",
    "df = diabetes.frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5e14f96-7893-4878-a5f5-a5b9e4c46d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column  Non-Null Count  Dtype   \n",
      "---  ------  --------------  -----   \n",
      " 0   preg    768 non-null    int64   \n",
      " 1   plas    768 non-null    int64   \n",
      " 2   pres    768 non-null    int64   \n",
      " 3   skin    768 non-null    int64   \n",
      " 4   insu    768 non-null    int64   \n",
      " 5   mass    768 non-null    float64 \n",
      " 6   pedi    768 non-null    float64 \n",
      " 7   age     768 non-null    int64   \n",
      " 8   class   768 non-null    category\n",
      "dtypes: category(1), float64(2), int64(6)\n",
      "memory usage: 49.0 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa26e52d-4388-4293-b515-6776d6632590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar caracteristicas (X) y etiqueta (Y)\n",
    "# Obtener los X eliminando la columna de etiqueta \n",
    "X = df.drop(columns=['class'])\n",
    "# Obtener Y convirtiendo la etiqueta en un valor numérico\n",
    "y = df['class'].apply(lambda x: 1 if x == 'tested_positive' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1565d8e5-c23c-4d50-bfdd-43dd4920fa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir el dataset en entrenamiento (80%) y prueba (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=26, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5bff197-bcc5-4113-af7c-851ec91d6c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estandarizar las caracteristicas (importante para el perceptron)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e35b31ff-23da-473f-8290-fe1d259cc7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tamaño del espacio latente (ruido de entrada para el generador)\n",
    "latent_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f216f6f8-06ca-49ee-ab4d-d4a8a3122ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generador():\n",
    "    model = Sequential([\n",
    "        Dense(32, input_dim=latent_dim),\n",
    "        LeakyReLU(0.2),\n",
    "        Dense(64),\n",
    "        LeakyReLU(0.2),\n",
    "        Dense(8, activation='tanh')  # Genera 8 características como X_train\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "826ac1d5-075a-472b-add0-42596113e953",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminador():\n",
    "    model = Sequential([\n",
    "        Dense(64, input_dim=8),\n",
    "        LeakyReLU(0.2),\n",
    "        Dense(32),\n",
    "        LeakyReLU(0.2),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c5cbbd8-fd3c-4210-8121-d9d0169326e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lisaj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Compilar el modelo \n",
    "discriminador = build_discriminador()\n",
    "discriminador.compile(\n",
    "    optimizer = Adam(learning_rate=0.0002, beta_1=0.5),\n",
    "    loss = 'binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3a79266-b1d2-46a0-bdc5-234b44e32456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilar el generador (dentro de la GAN)\n",
    "generador = build_generador()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d499ff2-a3f7-41aa-a65a-91aed2282b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Congelar el discriminador durante el entrenamiento del generador\n",
    "discriminador.trainable = False\n",
    "# Crear la GAN combinando el generador y el discriminador\n",
    "gan_input = tf.keras.Input(shape=(latent_dim,))\n",
    "gan_output = discriminador(generador(gan_input))\n",
    "gan = tf.keras.Model(gan_input, gan_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44c77132-52f0-4ce9-8b38-4da8ccceaa57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilar la GAN \n",
    "gan.compile(\n",
    "    optimizer = Adam(learning_rate=0.0002, beta_1=0.5),\n",
    "    loss = 'binary_crossentropy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1554d821-d1f6-4fe9-8b15-66cf3856b3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(\n",
    "    epoch, generator, ejemplos=16, dim=(4, 4), figsize=(10, 10)\n",
    "):\n",
    "    noise = np.random.normal(0, 1, size=(ejemplos, latent_dim))\n",
    "    generated_images = generator.predict(noise)\n",
    "    generated_images = generated_images.reshape(ejemplos, 28, 28)\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i in range(generated_images.shape[0]):\n",
    "        # crear una subgráfica para cada imagen generada\n",
    "        plt.subplot(dim[0], dim[1], i + 1)\n",
    "        plt.imshow(generated_images[i], interpolation=\"nearest\", cmap=\"gray_r\")\n",
    "        plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"gan_generated_epoch_{epoch}.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b59720aa-b225-4163-a182-669d3d9ffe03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gan(epochs=1000, batch_size=64):\n",
    "    batch_count = X_train.shape[0] // batch_size\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for _ in range(batch_count):\n",
    "            noise = np.random.normal(0, 1, size=(batch_size, latent_dim))\n",
    "            generated_data = generador.predict(noise, verbose=0)\n",
    "\n",
    "            real_data = X_train[np.random.randint(0, X_train.shape[0], size=batch_size)]\n",
    "\n",
    "            X_combined = np.concatenate([real_data, generated_data])\n",
    "            y_combined = np.concatenate([np.ones((batch_size, 1)), np.zeros((batch_size, 1))])\n",
    "\n",
    "            d_loss = discriminador.train_on_batch(X_combined, y_combined)\n",
    "            g_loss = gan.train_on_batch(noise, np.ones((batch_size, 1)))\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch} | Discriminator Loss: {d_loss[0]} | Generator Loss: {g_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c2520bd-2d79-4836-b65b-72c842ef74e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lisaj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:82: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Discriminator Loss: 0.7238147258758545 | Generator Loss: 0.7290153503417969\n",
      "Epoch 100 | Discriminator Loss: 0.8387024402618408 | Generator Loss: 0.5365782976150513\n",
      "Epoch 200 | Discriminator Loss: 0.8605435490608215 | Generator Loss: 0.5045706629753113\n",
      "Epoch 300 | Discriminator Loss: 0.8686620593070984 | Generator Loss: 0.49261409044265747\n",
      "Epoch 400 | Discriminator Loss: 0.8731999397277832 | Generator Loss: 0.48629555106163025\n",
      "Epoch 500 | Discriminator Loss: 0.8760713338851929 | Generator Loss: 0.4823617935180664\n",
      "Epoch 600 | Discriminator Loss: 0.8779171109199524 | Generator Loss: 0.47967514395713806\n",
      "Epoch 700 | Discriminator Loss: 0.8792669773101807 | Generator Loss: 0.4777219593524933\n",
      "Epoch 800 | Discriminator Loss: 0.8802993297576904 | Generator Loss: 0.4762371778488159\n",
      "Epoch 900 | Discriminator Loss: 0.8811635971069336 | Generator Loss: 0.4750687777996063\n",
      "Epoch 1000 | Discriminator Loss: 0.8818137645721436 | Generator Loss: 0.47412386536598206\n",
      "Epoch 1100 | Discriminator Loss: 0.8823847770690918 | Generator Loss: 0.4733445942401886\n",
      "Epoch 1200 | Discriminator Loss: 0.8828902840614319 | Generator Loss: 0.47268471121788025\n",
      "Epoch 1300 | Discriminator Loss: 0.8832389712333679 | Generator Loss: 0.47211953997612\n",
      "Epoch 1400 | Discriminator Loss: 0.8836373090744019 | Generator Loss: 0.4716350734233856\n",
      "Epoch 1500 | Discriminator Loss: 0.8839882016181946 | Generator Loss: 0.471215158700943\n",
      "Epoch 1600 | Discriminator Loss: 0.8842451572418213 | Generator Loss: 0.4708476960659027\n",
      "Epoch 1700 | Discriminator Loss: 0.8844890594482422 | Generator Loss: 0.4705234169960022\n",
      "Epoch 1800 | Discriminator Loss: 0.8847476243972778 | Generator Loss: 0.47023487091064453\n",
      "Epoch 1900 | Discriminator Loss: 0.8849456310272217 | Generator Loss: 0.46997499465942383\n",
      "Epoch 2000 | Discriminator Loss: 0.8850807547569275 | Generator Loss: 0.4697398841381073\n",
      "Epoch 2100 | Discriminator Loss: 0.885252058506012 | Generator Loss: 0.4695267677307129\n",
      "Epoch 2200 | Discriminator Loss: 0.8853908181190491 | Generator Loss: 0.4693331718444824\n",
      "Epoch 2300 | Discriminator Loss: 0.8855260610580444 | Generator Loss: 0.4691592752933502\n",
      "Epoch 2400 | Discriminator Loss: 0.8856009244918823 | Generator Loss: 0.4689998924732208\n",
      "Epoch 2500 | Discriminator Loss: 0.8856943845748901 | Generator Loss: 0.468853235244751\n",
      "Epoch 2600 | Discriminator Loss: 0.8858276009559631 | Generator Loss: 0.4687178432941437\n",
      "Epoch 2700 | Discriminator Loss: 0.8859267830848694 | Generator Loss: 0.46859249472618103\n",
      "Epoch 2800 | Discriminator Loss: 0.8860162496566772 | Generator Loss: 0.4684760868549347\n",
      "Epoch 2900 | Discriminator Loss: 0.8860884308815002 | Generator Loss: 0.46836772561073303\n",
      "Epoch 3000 | Discriminator Loss: 0.886184573173523 | Generator Loss: 0.4682665467262268\n",
      "Epoch 3100 | Discriminator Loss: 0.8862391114234924 | Generator Loss: 0.4681719243526459\n",
      "Epoch 3200 | Discriminator Loss: 0.8863086700439453 | Generator Loss: 0.4680832028388977\n",
      "Epoch 3300 | Discriminator Loss: 0.8863697052001953 | Generator Loss: 0.4679998755455017\n",
      "Epoch 3400 | Discriminator Loss: 0.8864264488220215 | Generator Loss: 0.4679214358329773\n",
      "Epoch 3500 | Discriminator Loss: 0.8865001797676086 | Generator Loss: 0.46784746646881104\n",
      "Epoch 3600 | Discriminator Loss: 0.8865429759025574 | Generator Loss: 0.4677776098251343\n",
      "Epoch 3700 | Discriminator Loss: 0.8865827322006226 | Generator Loss: 0.46771153807640076\n",
      "Epoch 3800 | Discriminator Loss: 0.8866353034973145 | Generator Loss: 0.4676489233970642\n",
      "Epoch 3900 | Discriminator Loss: 0.886677086353302 | Generator Loss: 0.46758952736854553\n",
      "Epoch 4000 | Discriminator Loss: 0.8867037892341614 | Generator Loss: 0.4675331115722656\n",
      "Epoch 4100 | Discriminator Loss: 0.8867455124855042 | Generator Loss: 0.4674794375896454\n",
      "Epoch 4200 | Discriminator Loss: 0.8867709040641785 | Generator Loss: 0.4674283266067505\n",
      "Epoch 4300 | Discriminator Loss: 0.8867982029914856 | Generator Loss: 0.4673795700073242\n",
      "Epoch 4400 | Discriminator Loss: 0.8868273496627808 | Generator Loss: 0.4673309922218323\n",
      "Epoch 4500 | Discriminator Loss: 0.8868653774261475 | Generator Loss: 0.4672757089138031\n",
      "Epoch 4600 | Discriminator Loss: 0.8869035840034485 | Generator Loss: 0.4672228693962097\n",
      "Epoch 4700 | Discriminator Loss: 0.8869367837905884 | Generator Loss: 0.4671722650527954\n",
      "Epoch 4800 | Discriminator Loss: 0.8869776725769043 | Generator Loss: 0.46712374687194824\n",
      "Epoch 4900 | Discriminator Loss: 0.8870322108268738 | Generator Loss: 0.46707722544670105\n",
      "Epoch 5000 | Discriminator Loss: 0.8870458602905273 | Generator Loss: 0.4670325815677643\n",
      "Epoch 5100 | Discriminator Loss: 0.8870718479156494 | Generator Loss: 0.466989666223526\n",
      "Epoch 5200 | Discriminator Loss: 0.8870906829833984 | Generator Loss: 0.46694839000701904\n",
      "Epoch 5300 | Discriminator Loss: 0.8871111273765564 | Generator Loss: 0.46690869331359863\n",
      "Epoch 5400 | Discriminator Loss: 0.8871434926986694 | Generator Loss: 0.4668704569339752\n",
      "Epoch 5500 | Discriminator Loss: 0.8871573209762573 | Generator Loss: 0.46683362126350403\n",
      "Epoch 5600 | Discriminator Loss: 0.8871791362762451 | Generator Loss: 0.4667980968952179\n",
      "Epoch 5700 | Discriminator Loss: 0.8872067928314209 | Generator Loss: 0.46676382422447205\n",
      "Epoch 5800 | Discriminator Loss: 0.8872242569923401 | Generator Loss: 0.4667307138442993\n",
      "Epoch 5900 | Discriminator Loss: 0.8872403502464294 | Generator Loss: 0.4666987359523773\n",
      "Epoch 6000 | Discriminator Loss: 0.8872516751289368 | Generator Loss: 0.4666678309440613\n",
      "Epoch 6100 | Discriminator Loss: 0.8872787356376648 | Generator Loss: 0.4666379392147064\n",
      "Epoch 6200 | Discriminator Loss: 0.8872988224029541 | Generator Loss: 0.46660900115966797\n",
      "Epoch 6300 | Discriminator Loss: 0.8873123526573181 | Generator Loss: 0.46658098697662354\n",
      "Epoch 6400 | Discriminator Loss: 0.8873307108879089 | Generator Loss: 0.46655383706092834\n",
      "Epoch 6500 | Discriminator Loss: 0.8873596787452698 | Generator Loss: 0.46652752161026\n",
      "Epoch 6600 | Discriminator Loss: 0.8873694539070129 | Generator Loss: 0.46650204062461853\n",
      "Epoch 6700 | Discriminator Loss: 0.887374997138977 | Generator Loss: 0.46647727489471436\n",
      "Epoch 6800 | Discriminator Loss: 0.8873891234397888 | Generator Loss: 0.4664532542228699\n",
      "Epoch 6900 | Discriminator Loss: 0.8873977065086365 | Generator Loss: 0.4664299488067627\n",
      "Epoch 7000 | Discriminator Loss: 0.8874140381813049 | Generator Loss: 0.46640726923942566\n",
      "Epoch 7100 | Discriminator Loss: 0.8874230980873108 | Generator Loss: 0.46638527512550354\n",
      "Epoch 7200 | Discriminator Loss: 0.8874357342720032 | Generator Loss: 0.4663638472557068\n",
      "Epoch 7300 | Discriminator Loss: 0.8874441981315613 | Generator Loss: 0.4663430452346802\n",
      "Epoch 7400 | Discriminator Loss: 0.8874561786651611 | Generator Loss: 0.46632277965545654\n",
      "Epoch 7500 | Discriminator Loss: 0.8874800205230713 | Generator Loss: 0.4663030505180359\n",
      "Epoch 7600 | Discriminator Loss: 0.8874960541725159 | Generator Loss: 0.4662838578224182\n",
      "Epoch 7700 | Discriminator Loss: 0.8875113725662231 | Generator Loss: 0.46626517176628113\n",
      "Epoch 7800 | Discriminator Loss: 0.8875247836112976 | Generator Loss: 0.46624693274497986\n",
      "Epoch 7900 | Discriminator Loss: 0.8875303864479065 | Generator Loss: 0.4662291705608368\n",
      "Epoch 8000 | Discriminator Loss: 0.8875470161437988 | Generator Loss: 0.46621185541152954\n",
      "Epoch 8100 | Discriminator Loss: 0.8875645399093628 | Generator Loss: 0.4661949872970581\n",
      "Epoch 8200 | Discriminator Loss: 0.8875763416290283 | Generator Loss: 0.4661785066127777\n",
      "Epoch 8300 | Discriminator Loss: 0.8875871300697327 | Generator Loss: 0.46616241335868835\n",
      "Epoch 8400 | Discriminator Loss: 0.8875926733016968 | Generator Loss: 0.4661467373371124\n",
      "Epoch 8500 | Discriminator Loss: 0.8875964879989624 | Generator Loss: 0.46613138914108276\n",
      "Epoch 8600 | Discriminator Loss: 0.8876065015792847 | Generator Loss: 0.46611642837524414\n",
      "Epoch 8700 | Discriminator Loss: 0.8876104950904846 | Generator Loss: 0.4661017954349518\n",
      "Epoch 8800 | Discriminator Loss: 0.8876215219497681 | Generator Loss: 0.4660874903202057\n",
      "Epoch 8900 | Discriminator Loss: 0.8876338601112366 | Generator Loss: 0.46607354283332825\n",
      "Epoch 9000 | Discriminator Loss: 0.8876355886459351 | Generator Loss: 0.4660598635673523\n",
      "Epoch 9100 | Discriminator Loss: 0.887642502784729 | Generator Loss: 0.4660465121269226\n",
      "Epoch 9200 | Discriminator Loss: 0.8876481056213379 | Generator Loss: 0.4660334289073944\n",
      "Epoch 9300 | Discriminator Loss: 0.8876604437828064 | Generator Loss: 0.4660206437110901\n",
      "Epoch 9400 | Discriminator Loss: 0.8876655101776123 | Generator Loss: 0.46600812673568726\n",
      "Epoch 9500 | Discriminator Loss: 0.8876757621765137 | Generator Loss: 0.4659958779811859\n",
      "Epoch 9600 | Discriminator Loss: 0.8876779079437256 | Generator Loss: 0.46598386764526367\n",
      "Epoch 9700 | Discriminator Loss: 0.8876861333847046 | Generator Loss: 0.4659721255302429\n",
      "Epoch 9800 | Discriminator Loss: 0.8876951336860657 | Generator Loss: 0.4659605920314789\n",
      "Epoch 9900 | Discriminator Loss: 0.8877028226852417 | Generator Loss: 0.46594932675361633\n"
     ]
    }
   ],
   "source": [
    "train_gan(epochs=10000, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b941ec5-ccdd-4463-a65c-9d8793c20499",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
